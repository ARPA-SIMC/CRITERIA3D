SF3Derror_t GPUSolver::inizialize()
{
    tempData.resize(nodeGrid.numNodes);
    if(_status != Created)
        return SolverError;

    if(_parameters.deltaTcurr == noData)
        _parameters.deltaTcurr = _parameters.deltaTmax;

    _parameters.enableOMP = true;                   //TO DO: (nodeGrid.numNodes > ...);

    numThreadsPerBlock = 64;                        //Must be multiple of warp-size(32)
    numBlocks = (uint64_t) ceil((double) nodeGrid.numNodes / numThreadsPerBlock);

    cuspCheck(cusparseCreate(&libHandle));

    //Inizialize matrix data
    iterationMatrix.numRows = static_cast<int64_t>(nodeGrid.numNodes);
    iterationMatrix.numCols = static_cast<int64_t>(nodeGrid.numNodes);
    iterationMatrix.sliceSize = static_cast<int64_t>(numThreadsPerBlock);
    uint64_t numSlice = numBlocks;
    uint64_t tnv = numSlice * iterationMatrix.sliceSize * (maxTotalLink + 1);
    iterationMatrix.totValuesSize = static_cast<int64_t>(tnv);

    deviceSolverAlloc(iterationMatrix.d_numColsInRow, uint64_t, iterationMatrix.numRows);

    deviceSolverAlloc(iterationMatrix.d_offsets, int64_t, (numSlice + 1));
    deviceSolverAlloc(iterationMatrix.d_columnIndeces, int64_t, tnv);
    deviceSolverAlloc(iterationMatrix.d_values, double, tnv);

    deviceSolverAlloc(iterationMatrix.d_diagonalValues, double, iterationMatrix.numRows);

    //Inizialize vectors data
    constantTerm.numElements = nodeGrid.numNodes;
    deviceSolverAlloc(constantTerm.d_values, double, constantTerm.numElements);

    unknownTerm.numElements = nodeGrid.numNodes;
    deviceSolverAlloc(unknownTerm.d_values, double, unknownTerm.numElements);

    tempSolution.numElements = nodeGrid.numNodes;
    deviceSolverAlloc(tempSolution.d_values, double, tempSolution.numElements);

    //Inizialize raw capacity vector
    deviceSolverAlloc(d_Cvalues, double, nodeGrid.numNodes);

    ptr = &(nodeGrid);
    _status = Inizialized;
    return SF3Dok;
}

SF3Derror_t GPUSolver::upCopyData()
{
    solverCheck(upMoveSoilSurfacePtr());      //Need to be done before moving nodeGrid.surfaceFlag

    //Topology Data
    moveToDevice(nodeGrid.size, double, nodeGrid.numNodes);
    moveToDevice(nodeGrid.x, double, nodeGrid.numNodes);
    moveToDevice(nodeGrid.y, double, nodeGrid.numNodes);
    moveToDevice(nodeGrid.z, double, nodeGrid.numNodes);
    moveToDevice(nodeGrid.surfaceFlag, bool, nodeGrid.numNodes);

    //Soil/surface properties pointers
    moveToDevice(nodeGrid.soilSurfacePointers, soil_surface_ptr, nodeGrid.numNodes);

    //Boundary data
    moveToDevice(nodeGrid.boundaryData.boundaryType, boundaryType_t, nodeGrid.numNodes);
    moveToDevice(nodeGrid.boundaryData.boundarySlope, double, nodeGrid.numNodes);
    moveToDevice(nodeGrid.boundaryData.boundarySize, double, nodeGrid.numNodes);
    if(simulationFlags.computeWater)
    {
        moveToDevice(nodeGrid.boundaryData.waterFlowRate, double, nodeGrid.numNodes);
        moveToDevice(nodeGrid.boundaryData.waterFlowSum, double, nodeGrid.numNodes);
        moveToDevice(nodeGrid.boundaryData.prescribedWaterPotential, double, nodeGrid.numNodes);
    }
    if(simulationFlags.computeHeat)
    {
        //TO DO: (heat)
    }

    //Link data
    moveToDevice(nodeGrid.numLateralLink, uint8_t, nodeGrid.numNodes);
    for(uint8_t idx = 0; idx < maxTotalLink; ++idx)
    {
        moveToDevice(nodeGrid.linkData[idx].linktype, linkType_t, nodeGrid.numNodes);
        moveToDevice(nodeGrid.linkData[idx].linkIndex, uint64_t, nodeGrid.numNodes);
        moveToDevice(nodeGrid.linkData[idx].interfaceArea, double, nodeGrid.numNodes);
        if(simulationFlags.computeWater)
            moveToDevice(nodeGrid.linkData[idx].waterFlowSum, double, nodeGrid.numNodes);
    }

    //Water data
    if(simulationFlags.computeWater)
    {
        moveToDevice(nodeGrid.waterData.saturationDegree, double, nodeGrid.numNodes);
        moveToDevice(nodeGrid.waterData.waterConductivity, double, nodeGrid.numNodes);
        moveToDevice(nodeGrid.waterData.waterFlow, double, nodeGrid.numNodes);
        moveToDevice(nodeGrid.waterData.pressureHead, double, nodeGrid.numNodes);
        moveToDevice(nodeGrid.waterData.waterSinkSource, double, nodeGrid.numNodes);
        moveToDevice(nodeGrid.waterData.pond, double, nodeGrid.numNodes);
        moveToDevice(nodeGrid.waterData.invariantFluxes, double, nodeGrid.numNodes);
        moveToDevice(nodeGrid.waterData.oldPressureHeads, double, nodeGrid.numNodes);
        moveToDevice(nodeGrid.waterData.bestPressureHeads, double, nodeGrid.numNodes);
    }

    //Heat data
    if(simulationFlags.computeHeat)
    {
        //TO DO: (heat)
    }

    //Move the solver object data
    //moveToDevice(solver, Solver, 1);

    return SF3Dok;
}

SF3Derror_t GPUSolver::downCopyData()
{
    //Topology Data
    uint64_t temp = nodeGrid.numNodes;

    moveToHost(nodeGrid.size, double, nodeGrid.numNodes);
    moveToHost(nodeGrid.x, double, nodeGrid.numNodes);
    moveToHost(nodeGrid.y, double, nodeGrid.numNodes);
    moveToHost(nodeGrid.z, double, nodeGrid.numNodes);
    moveToHost(nodeGrid.surfaceFlag, bool, nodeGrid.numNodes);

    //Soil/surface properties pointers
    moveToHost(nodeGrid.soilSurfacePointers, soil_surface_ptr, nodeGrid.numNodes);

    //Boundary data
    moveToHost(nodeGrid.boundaryData.boundaryType, boundaryType_t, nodeGrid.numNodes);
    moveToHost(nodeGrid.boundaryData.boundarySlope, double, nodeGrid.numNodes);
    moveToHost(nodeGrid.boundaryData.boundarySize, double, nodeGrid.numNodes);
    if(simulationFlags.computeWater)
    {
        moveToHost(nodeGrid.boundaryData.waterFlowRate, double, nodeGrid.numNodes);
        moveToHost(nodeGrid.boundaryData.waterFlowSum, double, nodeGrid.numNodes);
        moveToHost(nodeGrid.boundaryData.prescribedWaterPotential, double, nodeGrid.numNodes);
    }
    if(simulationFlags.computeHeat)
    {
        //TO DO: (heat)
    }

    //Link data
    moveToHost(nodeGrid.numLateralLink, uint8_t, nodeGrid.numNodes);
    for(uint8_t idx = 0; idx < maxTotalLink; ++idx)
    {
        moveToHost(nodeGrid.linkData[idx].linktype, linkType_t, nodeGrid.numNodes);
        moveToHost(nodeGrid.linkData[idx].linkIndex, uint64_t, nodeGrid.numNodes);
        moveToHost(nodeGrid.linkData[idx].interfaceArea, double, nodeGrid.numNodes);
        if(simulationFlags.computeWater)
            moveToHost(nodeGrid.linkData[idx].waterFlowSum, double, nodeGrid.numNodes);
    }

    //Water data
    if(simulationFlags.computeWater)
    {
        moveToHost(nodeGrid.waterData.saturationDegree, double, nodeGrid.numNodes);
        moveToHost(nodeGrid.waterData.waterConductivity, double, nodeGrid.numNodes);
        moveToHost(nodeGrid.waterData.waterFlow, double, nodeGrid.numNodes);
        moveToHost(nodeGrid.waterData.pressureHead, double, nodeGrid.numNodes);
        moveToHost(nodeGrid.waterData.waterSinkSource, double, nodeGrid.numNodes);
        moveToHost(nodeGrid.waterData.pond, double, nodeGrid.numNodes);
        moveToHost(nodeGrid.waterData.invariantFluxes, double, nodeGrid.numNodes);
        moveToHost(nodeGrid.waterData.oldPressureHeads, double, nodeGrid.numNodes);
        moveToHost(nodeGrid.waterData.bestPressureHeads, double, nodeGrid.numNodes);
    }

    //Heat data
    if(simulationFlags.computeHeat)
    {
        //TO DO: (heat)
    }

    solverCheck(downMoveSoilSurfacePtr());      //Need to be done after moving nodeGrid.surfaceFlag

    //Move the solver object data
    //moveToHost(solver, Solver, 1);
    return SF3Dok;
}

SF3Derror_t GPUSolver::createCUsparseDescriptors()
{
    int64_t *d_nnz = nullptr;
    cudaMalloc((void**) &d_nnz, sizeof(int64_t));

    void* d_tempStorage = nullptr;
    size_t tempStorageSize = 0;
    cub::DeviceReduce::Sum(d_tempStorage, tempStorageSize, iterationMatrix.d_numColsInRow, d_nnz, iterationMatrix.numRows);
    cudaMalloc(&d_tempStorage, tempStorageSize);
    cub::DeviceReduce::Sum(d_tempStorage, tempStorageSize, iterationMatrix.d_numColsInRow, d_nnz, iterationMatrix.numRows);
    cudaMemcpy(&(iterationMatrix.numNonZeroElement), d_nnz, sizeof(int64_t), cudaMemcpyDeviceToHost);

    //Create matrix descriptor
    cuspCheck(cusparseCreateSlicedEll(&(iterationMatrix.cusparseDescriptor),
                                        iterationMatrix.numRows, iterationMatrix.numCols, iterationMatrix.numNonZeroElement, iterationMatrix.totValuesSize, iterationMatrix.sliceSize,
                                        iterationMatrix.d_offsets, iterationMatrix.d_columnIndeces,  iterationMatrix.d_values,
                                        iterationMatrix.offsetType, iterationMatrix.colIdxType, iterationMatrix.idxBase, iterationMatrix.valueType));

    //Create vector descriptor
    cuspCheck(cusparseCreateDnVec(&(constantTerm.cusparseDescriptor), constantTerm.numElements, constantTerm.d_values, constantTerm.valueType));
    cuspCheck(cusparseCreateDnVec(&(unknownTerm.cusparseDescriptor), unknownTerm.numElements, unknownTerm.d_values, unknownTerm.valueType));
    cuspCheck(cusparseCreateDnVec(&(tempSolution.cusparseDescriptor), tempSolution.numElements, tempSolution.d_values, tempSolution.valueType));

    return SF3Dok;
}

SF3Derror_t GPUSolver::run(double maxTimeStep, double &acceptedTimeStep, processType process)
{
    if(_status != Inizialized)
        return SolverError;

    solverCheck(upCopyData());

    switch (process)
    {
        case Water:
            waterMainLoop(maxTimeStep, acceptedTimeStep);
            break;
        case Heat:
            break;
        case Solutes:
            break;
        default:
            break;
    }

    solverCheck(downCopyData());

    _status = Terminated;
    _status = Inizialized;
    return SF3Dok;
}

SF3Derror_t GPUSolver::clean()
{
    if(_status == Created)
        return SF3Dok;

    if((_status != Terminated) && (_status != Inizialized))
        return SolverError;

    _status = Created;
    return SF3Dok;
}


void GPUSolver::waterMainLoop(double maxTimeStep, double &acceptedTimeStep)
{
    balanceResult_t stepStatus = stepRefused;
    while(stepStatus != stepAccepted)
    {
        acceptedTimeStep = SF3Dmin(_parameters.deltaTcurr, maxTimeStep);

        //Save instantaneus H values
        cudaCheckSolver(cudaMemcpy(nodeGrid.waterData.oldPressureHeads, nodeGrid.waterData.pressureHead, nodeGrid.numNodes * sizeof(double), cudaMemcpyDeviceToDevice));

        //Inizialize the solution vector with the current pressure head
        cudaCheckSolver(cudaMemcpy(unknownTerm.d_values, nodeGrid.waterData.pressureHead, unknownTerm.numElements * sizeof(double), cudaMemcpyDeviceToDevice));

        //Assign vectorC surface values and compute subsurface saturation degree
        launchKernel(init_SurfaceC_SubSurfaceSe, d_Cvalues);

        //tempCopy(d_Cvalues);
        //tempCopy(nodeGrid.waterData.saturationDegree);

        //Update aereodynamic and soil conductance
        //updateConductance();      //TO DO (Heat)

        //Update boundary
        launchKernel(updateBoundaryWaterData_k, acceptedTimeStep);

        //Effective computation step
        stepStatus = waterApproximationLoop(acceptedTimeStep);

        //Restore pressure head if step non successuful
        if(stepStatus != stepAccepted)
            cudaCheckSolver(cudaMemcpy(nodeGrid.waterData.pressureHead, nodeGrid.waterData.oldPressureHeads, nodeGrid.numNodes * sizeof(double), cudaMemcpyDeviceToDevice));
    }
}

balanceResult_t GPUSolver::waterApproximationLoop(double deltaT)
{
    balanceResult_t balanceResult;

    for(uint8_t approxIdx = 0; approxIdx < _parameters.maxApproximationsNumber; ++approxIdx)
    {
        //Compute capacity vector elements
        launchKernel(computeCapacity_k, d_Cvalues);

        cudaDeviceSynchronize();
        tempCopy(d_Cvalues);

        //Update boundary water
        launchKernel(updateBoundaryWaterData_k, deltaT);

        //Update Courant data
        nodeGrid.waterData.CourantWaterLevel = 0.;

        //Compute linear system elements
        launchKernel(computeLinearSystemElement_k, iterationMatrix, constantTerm, d_Cvalues, approxIdx, deltaT, _parameters.lateralVerticalRatio, _parameters.meantype);

        //Inizialize cusparse descriptors
        createCUsparseDescriptors();

        //Check Courant
        if((nodeGrid.waterData.CourantWaterLevel > 1.) && (deltaT > _parameters.deltaTmin))
        {
            _parameters.deltaTcurr = SF3Dmax(_parameters.deltaTmin, _parameters.deltaTcurr / nodeGrid.waterData.CourantWaterLevel);
            if(_parameters.deltaTcurr > 1.)
                _parameters.deltaTcurr = floor(_parameters.deltaTcurr);

            return stepHalved;
        }

        //Try solve linear system
        bool isStepValid = solveLinearSystem(approxIdx, Water);

        //Reduce step tipe if system resolution failed
        if((!isStepValid) && (deltaT > _parameters.deltaTmin))
        {
            _parameters.deltaTcurr = SF3Dmax(_parameters.deltaTmin, _parameters.deltaTcurr / 2.);
            return stepHalved;
        }

        //Update potential
        assert(unknownTerm.numElements == nodeGrid.numNodes);
        cudaMemcpy(nodeGrid.waterData.pressureHead, unknownTerm.d_values, nodeGrid.numNodes * sizeof(double), cudaMemcpyDeviceToDevice);

        //Update degree of saturation
        launchKernel(updateSaturationDegree_k);

        //Check water balance
        downCopyData();
        balanceResult = evaluateWaterBalance(approxIdx, _bestMBRerror, deltaT,  _parameters);
        upCopyData();

        if((balanceResult == stepAccepted) || (balanceResult == stepHalved))
            return balanceResult;
    }
    //TO DO: log functions

    return balanceResult;
}

bool GPUSolver::solveLinearSystem(uint8_t approximationNumber, processType computationType) //Implemented only Jacobi Water
{
    size_t bufSize;
    const double alpha = -1, beta = 1;
    void *externalBuffer;

    cusparseSpMV_bufferSize(libHandle, CUSPARSE_OPERATION_NON_TRANSPOSE, &alpha, iterationMatrix.cusparseDescriptor, unknownTerm.cusparseDescriptor, &beta, tempSolution.cusparseDescriptor, CUDA_R_64F, CUSPARSE_SPMV_ALG_DEFAULT, &bufSize);
    cudaDeviceSynchronize();
    cudaMalloc(&externalBuffer, bufSize);

    bool status = true;
    double bestErrorNorm = (double) std::numeric_limits<float>::max();

    cudaError_t err;

    //TO DO: implement cusparseSpMV_preprocess

    uint32_t currMaxIterationNum = calcCurrentMaxIterationNumber(approximationNumber);
    uint32_t GPUfactor = 1;           //TO DO: test and optimize
    for (size_t iterationNumber = 0; iterationNumber < currMaxIterationNum; ++iterationNumber)
    {
        for(size_t internalCounter = 0; internalCounter < GPUfactor; ++internalCounter)
        {
            cudaMemcpy(tempSolution.d_values, constantTerm.d_values, constantTerm.numElements * sizeof(double), cudaMemcpyDeviceToDevice);
            cudaDeviceSynchronize();
            err = cudaGetLastError();

            cusparseSpMV(libHandle, CUSPARSE_OPERATION_NON_TRANSPOSE, &alpha, iterationMatrix.cusparseDescriptor, unknownTerm.cusparseDescriptor, &beta, tempSolution.cusparseDescriptor, CUDA_R_64F, CUSPARSE_SPMV_ALG_DEFAULT, externalBuffer);
            cudaDeviceSynchronize();
            err = cudaGetLastError();

            //TEMP: single iteration to mimic CPU behaviour
            double *d_tempVector = nullptr;
            cudaMalloc((void**) &d_tempVector, unknownTerm.numElements * sizeof(double));
            cudaMemcpy(d_tempVector, unknownTerm.d_values, constantTerm.numElements * sizeof(double), cudaMemcpyDeviceToDevice);
            cudaDeviceSynchronize();
            err = cudaGetLastError();
            cudaMemcpy(unknownTerm.d_values, tempSolution.d_values, constantTerm.numElements * sizeof(double), cudaMemcpyDeviceToDevice);
            cudaDeviceSynchronize();
            err = cudaGetLastError();
            cudaMemcpy(tempSolution.d_values, d_tempVector, constantTerm.numElements * sizeof(double), cudaMemcpyDeviceToDevice);
            cudaDeviceSynchronize();
            err = cudaGetLastError();
            cudaFree(d_tempVector); d_tempVector = nullptr;

            //cudaMemcpy(unknownTerm.d_values, constantTerm.d_values, constantTerm.numElements * sizeof(double), cudaMemcpyDeviceToDevice);
            //cudaDeviceSynchronize();

            //cusparseSpMV(libHandle, CUSPARSE_OPERATION_NON_TRANSPOSE, &alpha, iterationMatrix.cusparseDescriptor, tempSolution.cusparseDescriptor, &beta, unknownTerm.cusparseDescriptor, CUDA_R_64F, CUSPARSE_SPMV_ALG_DEFAULT, externalBuffer);
            //cudaDeviceSynchronize();

        }

        tempCopy(unknownTerm.d_values);

        //Calcolo della norma dell'errore
        double currErrorNorm = 0;
        double *d_normValue = nullptr, *d_normVector = nullptr;
        cudaMalloc((void**) &d_normValue, sizeof(double));
        cudaMalloc((void**) &d_normVector, unknownTerm.numElements * sizeof(double));
        launchKernel(computeNormalizedError, d_normVector, unknownTerm.d_values, tempSolution.d_values);

        err = cudaGetLastError();

        tempCopy(d_normValue);

        void* d_tempStorage = nullptr;
        size_t tempStorageSize = 0;
        cub::DeviceReduce::Max(d_tempStorage, tempStorageSize, d_normVector, d_normValue, unknownTerm.numElements);
        cudaMalloc(&d_tempStorage, tempStorageSize);
        cub::DeviceReduce::Max(d_tempStorage, tempStorageSize, d_normVector, d_normValue, unknownTerm.numElements);
        cudaMemcpy(&currErrorNorm, d_normValue, sizeof(double), cudaMemcpyDeviceToHost);

        if(currErrorNorm < _parameters.residualTolerance)
            break;

        if(currErrorNorm > (bestErrorNorm * 10))
            status = false;

        if(currErrorNorm < bestErrorNorm)
            bestErrorNorm = currErrorNorm;
    }

    cudaFree(externalBuffer);
    return status;
}

SF3Derror_t GPUSolver::upMoveSoilSurfacePtr()
{
    //Move surface data
    size_t surfaceSize = surfaceList.size() * sizeof(surfaceData_t);
    cudaCheck(cudaMalloc((void**) &d_surfaceList, surfaceSize));
    cudaCheck(cudaMemcpy(d_surfaceList, surfaceList.data(), surfaceSize, cudaMemcpyHostToDevice));


    //Flat soil data
    size_t soilSize = 0;
    std::vector<soilData_t> soilList1D;
    std::vector<size_t> listOffsets;
    listOffsets.reserve(soilList.size());
    for (auto soilRow : soilList)
    {
        listOffsets.push_back(soilSize);
        soilSize += soilRow.size();
        soilList1D.insert(soilList1D.end(), soilRow.begin(), soilRow.end());
    }

    //Move soil data
    soilSize *= sizeof(soilData_t);
    cudaCheck(cudaMalloc((void**) &d_soilList, soilSize));
    cudaCheck(cudaMemcpy(d_soilList, soilList1D.data(), soilSize, cudaMemcpyHostToDevice));

    #pragma omp parallel for if(_parameters.enableOMP)
    for(uint64_t nodeIndex = 0; nodeIndex < nodeGrid.numNodes; ++nodeIndex)
    {
        ptrdiff_t currOffset;
        if(nodeGrid.surfaceFlag[nodeIndex])
        {
            currOffset = nodeGrid.soilSurfacePointers[nodeIndex].surfacePtr - surfaceList.data();
            nodeGrid.soilSurfacePointers[nodeIndex].surfacePtr = d_surfaceList + currOffset;
        }
        else
        {
            uint16_t soilRowIndex = nodeGrid.soilRowIndeces[nodeIndex];
            currOffset = listOffsets[soilRowIndex] + (nodeGrid.soilSurfacePointers[nodeIndex].soilPtr - soilList[soilRowIndex].data());
            nodeGrid.soilSurfacePointers[nodeIndex].soilPtr = d_soilList + currOffset;
        }
    }
    return SF3Dok;
}

SF3Derror_t GPUSolver::downMoveSoilSurfacePtr()
{
    //Flat soil data
    size_t soilSize = 0;
    std::vector<size_t> listOffsets;
    listOffsets.reserve(soilList.size());
    for (auto soilRow : soilList)
    {
        listOffsets.push_back(soilSize);
        soilSize += soilRow.size();
    }

    #pragma omp parallel for if(_parameters.enableOMP)
    for(uint64_t nodeIndex = 0; nodeIndex < nodeGrid.numNodes; ++nodeIndex)
    {
        ptrdiff_t currOffset;
        if(nodeGrid.surfaceFlag[nodeIndex])
        {
            currOffset = nodeGrid.soilSurfacePointers[nodeIndex].surfacePtr - d_surfaceList;
            nodeGrid.soilSurfacePointers[nodeIndex].surfacePtr = surfaceList.data() + currOffset;
        }
        else
        {
            uint16_t soilRowIndex = nodeGrid.soilRowIndeces[nodeIndex];
            currOffset = nodeGrid.soilSurfacePointers[nodeIndex].soilPtr - (d_soilList + listOffsets[soilRowIndex]);
            nodeGrid.soilSurfacePointers[nodeIndex].soilPtr = soilList[soilRowIndex].data();
        }
    }

    deviceSolverFree(d_surfaceList);
    deviceSolverFree(d_soilList);
    return SF3Dok;
}


//-------------------------------- CUDA KERNELS --------------------------------

extern __cudaMngd Solver* solver;

__global__ void init_SurfaceC_SubSurfaceSe(double* vectorC)         //TO DO: merge with host code in single __host__ __device__ function
{
    uint64_t nodeIdx = (blockIdx.x * blockDim.x) + threadIdx.x;
    if(nodeIdx >= nodeGrid.numNodes)
        return;

    if(nodeGrid.surfaceFlag[nodeIdx])
        vectorC[nodeIdx] = nodeGrid.size[nodeIdx];
    else
        nodeGrid.waterData.saturationDegree[nodeIdx] = computeNodeSe(nodeIdx);
}

__global__ void updateBoundaryWaterData_k(double deltaT)            //TO DO: merge with host code in single __host__ __device__ function
{
    uint64_t nodeIdx = (blockIdx.x * blockDim.x) + threadIdx.x;
    if(nodeIdx >= nodeGrid.numNodes)
        return;

    nodeGrid.waterData.waterFlow[nodeIdx] = nodeGrid.waterData.waterSinkSource[nodeIdx];

    if(nodeGrid.boundaryData.boundaryType[nodeIdx] == NoBoundary)
        return;

    switch(nodeGrid.boundaryData.boundaryType[nodeIdx])
    {
        case Runoff:
            double avgH, hs, maxFlow, v, flow;
            avgH = 0.5 * (nodeGrid.waterData.pressureHead[nodeIdx] + nodeGrid.waterData.oldPressureHeads[nodeIdx]);

            hs = SF3Dmax(0., avgH - (nodeGrid.z[nodeIdx] + nodeGrid.waterData.pond[nodeIdx]));
            if(hs < EPSILON_RUNOFF)
                break;

            // Maximum flow available during the time step [m3 s-1]
            maxFlow = (hs * nodeGrid.size[nodeIdx]) / deltaT;

            //Manning equation
            assert(nodeGrid.surfaceFlag[nodeIdx]);
            v = pow(hs, 2./3.) * sqrt(nodeGrid.boundaryData.boundarySlope[nodeIdx]) / nodeGrid.soilSurfacePointers[nodeIdx].surfacePtr->roughness;

            flow = hs * v * nodeGrid.boundaryData.boundarySize[nodeIdx];
            nodeGrid.boundaryData.waterFlowRate[nodeIdx] = -SF3Dmin(flow, maxFlow);
            break;

        case FreeDrainage:
            //Darcy unit gradient (use link node up)
            assert(nodeGrid.linkData[0].linktype[nodeIdx] != NoLink);
            nodeGrid.boundaryData.waterFlowRate[nodeIdx] = -nodeGrid.waterData.waterConductivity[nodeIdx] * nodeGrid.linkData[0].interfaceArea[nodeIdx];
            break;

        case FreeLateraleDrainage:
            //Darcy gradient = slope
            double LVratio;
            LVratio = 10; // TO DO: solver.getLVRatio();
            nodeGrid.boundaryData.waterFlowRate[nodeIdx] = -nodeGrid.waterData.waterConductivity[nodeIdx] * nodeGrid.boundaryData.boundarySize[nodeIdx]
                                                               * nodeGrid.boundaryData.boundarySlope[nodeIdx] * LVratio;
            break;

        case PrescribedTotalWaterPotential:
            double L, boundaryPsi, boundaryZ, boundaryK, meanK, dH;
            L = 1.;     // [m]
            boundaryZ = nodeGrid.z[nodeIdx] - L;

            boundaryPsi = nodeGrid.boundaryData.prescribedWaterPotential[nodeIdx] - boundaryZ;

            boundaryK = (boundaryPsi >= 0)  ? nodeGrid.soilSurfacePointers[nodeIdx].soilPtr->K_sat
                                           : computeNodeK_Mualem(*(nodeGrid.soilSurfacePointers[nodeIdx].soilPtr), computeNodeSe_fromPsi(nodeIdx, fabs(boundaryPsi)));

            meanType_t meanType;
            meanType = Logarithmic; //TO DO: solver.getMeanType()
            meanK = computeMean(boundaryK, nodeGrid.waterData.waterConductivity[nodeIdx], meanType);
            dH = nodeGrid.boundaryData.prescribedWaterPotential[nodeIdx] - nodeGrid.waterData.pressureHead[nodeIdx];

            nodeGrid.boundaryData.waterFlowRate[nodeIdx] = meanK * nodeGrid.boundaryData.boundarySize[nodeIdx] * (dH / L);
            break;

        case HeatSurface:
            if(!simulationFlags.computeHeat && !simulationFlags.computeHeatVapor)
                break;
            //TO DO: complete

            break;

        default:
            nodeGrid.boundaryData.waterFlowRate[nodeIdx] = 0.;
            break;
    }

    if(abs(nodeGrid.boundaryData.waterFlowRate[nodeIdx]) < DBL_EPSILON)
        nodeGrid.boundaryData.waterFlowRate[nodeIdx] = 0.;
    else
        nodeGrid.waterData.waterFlow[nodeIdx] += nodeGrid.boundaryData.waterFlowRate[nodeIdx];
}

__global__ void updateSaturationDegree_k()
{
    uint64_t nodeIdx = (blockIdx.x * blockDim.x) + threadIdx.x;
    if(nodeIdx >= nodeGrid.numNodes)
        return;

    if(!nodeGrid.surfaceFlag[nodeIdx])
        nodeGrid.waterData.saturationDegree[nodeIdx] = computeNodeSe(nodeIdx);
}

__global__ void computeCapacity_k(double *vectorC)
{
    uint64_t nodeIdx = (blockIdx.x * blockDim.x) + threadIdx.x;
    if(nodeIdx >= nodeGrid.numNodes)
        return;

    nodeGrid.waterData.invariantFluxes[nodeIdx] = 0.;
    if(nodeGrid.surfaceFlag[nodeIdx])
        return;

    //Compute hydraulic conductivity
    nodeGrid.waterData.waterConductivity[nodeIdx] = computeNodeK(nodeIdx);

    double dThetadH = computeNodedThetadH(nodeIdx);
    vectorC[nodeIdx] = nodeGrid.size[nodeIdx] * dThetadH;

    //TO DO: (heat)
    //if(simulationFlags.computeHeat && simulationFlags.computeHeatVapor)
    //    vectorC.values[nodeIndex] += nodeGrid.size[nodeIndex] * computeNodedThetaVdH(nodeIndex, getNodeMeanTemperature(nodeIndex), dThetadH);
}

__global__ void computeLinearSystemElement_k(MatrixGPU matrixA, VectorGPU vectorB, const double* Cvalues, uint8_t approxNum, double deltaT, double lateralVerticalRatio, meanType_t meanType)
{
    uint64_t sliceIdx = blockIdx.x;
    uint64_t rowIdx = (blockIdx.x * blockDim.x) + threadIdx.x;
    if(rowIdx >= nodeGrid.numNodes)
        return;

    uint64_t linearBaseIndex = (sliceIdx * blockDim.x * maxTotalLink) + threadIdx.x;

    bool isLinked;
    uint8_t linkIdx = 0;

    uint64_t linearFullIndex = linearBaseIndex + (linkIdx * blockDim.x);
    uint64_t tempIndex;     //TO check...

    isLinked = computeLinkFluxes(matrixA.d_values[linearFullIndex], tempIndex, rowIdx, 0, approxNum, deltaT, lateralVerticalRatio, Up, meanType);
    matrixA.d_columnIndeces[linearFullIndex] = static_cast<int64_t>(tempIndex);
    if(isLinked)
        linearFullIndex = linearBaseIndex + ((++linkIdx) * blockDim.x);

    //compute flox down
    isLinked = computeLinkFluxes(matrixA.d_values[linearFullIndex], tempIndex, rowIdx, 1, approxNum, deltaT, lateralVerticalRatio, Down, meanType);
    matrixA.d_columnIndeces[linearFullIndex] = static_cast<int64_t>(tempIndex);
    if(isLinked)
        linearFullIndex = linearBaseIndex + ((++linkIdx) * blockDim.x);

    //compute flux lateral
    for(uint8_t latIdx = 0; latIdx < maxLateralLink; ++latIdx)
    {
        isLinked = computeLinkFluxes(matrixA.d_values[linearFullIndex], tempIndex, rowIdx, 2 + latIdx, approxNum, deltaT, lateralVerticalRatio, Lateral, meanType);
        matrixA.d_columnIndeces[linearFullIndex] = static_cast<int64_t>(tempIndex);
        if(isLinked)
            linearFullIndex = linearBaseIndex + ((++linkIdx) * blockDim.x);
    }

    matrixA.d_numColsInRow[rowIdx] = linkIdx;

    //Fill not used columns with -1
    for(uint8_t colIdx = linkIdx; colIdx < maxTotalLink; ++colIdx)
        matrixA.d_columnIndeces[linearBaseIndex + (colIdx * blockDim.x)] = -1;

    //Compute diagonal element
    double sum = 0.;
    for(uint8_t colIdx = 1; colIdx < matrixA.d_numColsInRow[rowIdx]; ++colIdx)
    {
        sum += matrixA.d_values[linearBaseIndex + (colIdx * blockDim.x)];
        matrixA.d_values[linearBaseIndex + (colIdx * blockDim.x)] *= -1.;
    }
    matrixA.d_diagonalValues[rowIdx] = (Cvalues[rowIdx] / deltaT) + sum;

    //Compute b element
    vectorB.d_values[rowIdx] = ((Cvalues[rowIdx] / deltaT) * nodeGrid.waterData.oldPressureHeads[rowIdx]) + nodeGrid.waterData.waterFlow[rowIdx] + nodeGrid.waterData.invariantFluxes[rowIdx];

    //Preconditioning
    for(uint8_t colIdx = 0; colIdx < matrixA.d_numColsInRow[rowIdx]; ++colIdx)
        matrixA.d_values[linearBaseIndex + (colIdx * blockDim.x)] /= matrixA.d_diagonalValues[rowIdx];

    vectorB.d_values[rowIdx] /= matrixA.d_diagonalValues[rowIdx];
}

__global__ void computeNormalizedError(double *vectorNorm, double *vectorX, const double *previousX)
{
    uint64_t nodeIdx = (blockIdx.x * blockDim.x) + threadIdx.x;
    if(nodeIdx >= nodeGrid.numNodes)
        return;

    if(nodeGrid.surfaceFlag[nodeIdx] && vectorX[nodeIdx] < nodeGrid.z[nodeIdx])
        vectorX[nodeIdx] = nodeGrid.z[nodeIdx];

    double currentNorm = fabs(vectorX[nodeIdx] - previousX[nodeIdx]);
    double psi = fabs(vectorX[nodeIdx] - nodeGrid.z[nodeIdx]);
    if(psi > 1.)
        currentNorm /= psi;

    vectorNorm[nodeIdx] = currentNorm;
}
